---
layout: post
title: Board games, AI, and real-world markets (part I)
date: 2019-08-04
author: Jan Sauer
description: Games are an ideal proxy for complex market dynamics. The strategies learned by AI models to win these games can help analyze and identify the optimal decisions in these environments.
categories: [Software Development, Board Games]
---

{% assign img_dir = page.path | split: "/" | last | split: "." | first %}

Games have become a popular testing ground for reinforcement learning, as they require complex strategies to successfully play and win. Whether board games, such as [AlphaGo](https://en.wikipedia.org/wiki/AlphaGo), or computer games, such as [StarCraft](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/), different games offer diverse challenges for artificial intelligence.

Typically, the goal is to design and train a model that can outperform highly-rated human players at a deterministic game. That means, the game has no source of randomness and the outcome is determined solely by players' actions. However, introducing randomness, or risk, can notably change player strategies. For example, an attacking chess piece will conventionally always win a confrontation. However, a player's strategy would change considerably if an attach only had a 70% probability of success. Aggressive strategies now come with an inherent risk that must be weighed against the potential benefits of an attack.

Randomness, e.g. through dice rolls, can be used to simulate the complex dynamics of competitive markets, where not all parameters may be known or measurable. The strategies that AI models develop to deal with this randomness in turn serve as proxies for decision-making strategies in real-world scenarios.

This risk and the strategies AI models develop to deal with it are an ideal proxy for decision-making processes in real-world scenarios.

This project aims to understand the decision-making process in a competitive market with limited resources. The proxy for this scenario is the board game _[Camel Up](https://en.wikipedia.org/wiki/Camel_Up)_ by _Pegasus Spiele_. The core mechanics of the game involve placing bets on camels on a race track. The game is divided into 'rounds', in which each of the camels are moved a random number of spaces and in a random order. Dice rolls determine which camel moves and how far. The camel race is separated into __rounds__, consisting of a single move for each camel. That consequently means that each camel must move once before any can move again.

During this ongoing race, players can choose one of four actions each turn:

- move a random camel along the track by rolling dice (the player has no control over which camel moves beyond the limitation that each camel must move before they can move again),
- place traps to impede or help camels that land on them,
- make a bet on which camel will be furthest along at the end of the current round, or
- make a bet on which camel will win or lose the entire game.

The game's difficult stems from the fact that camels can stack on top of each other if they land on the same space. If a camel is moved, all camels on top of it in the stack are also moved. This adds a layer of complexity to the game that makes it nearly impossible to predict which camel will win the race, or even the current round.

In the first part of this series, I will introduce my implementation of a digital version of Camel Up.

# Simulating Camel Up
This project was inspired by Tyler Barron's [Camel Up Cup 2k18](http://tylerbarron.com/CamelUpCup.html) and his [code](https://github.com/trbarron/Camel_Up_Cup_2K18) was used as a basis for this implementation. However, the code was buggy and/or incomplete and lacked the flexibility I wanted, so I dramatically expanded it and created what appears at first glance to be a rewrite with a number of "plagiarized" code blocks. For this reason, this code is published under the same open-source license as Tyler's original project.

The full code base can be found on my (GitHub repository)[https://github.com/DragonDuck/CamelAI].

The rest of this post will discuss the code in detail and make references to file names as they appear in the aforementioned (repository)[https://github.com/DragonDuck/CamelAI]. I assume the reader knows the rules of Camel Up.

This game is implemented in Python to later make use of the extensive machine and deep learning tools available for the Python programming language.

## Components

My implementation consists of three components:

1. Game engine: keeps track of player actions and the current game state,
2. Rules engine: determines which actions are permissible and which are forbidden based on the current game state,
3. Player bots: decide, on the basis of the current game state, which actions to execute.

![Game Flowchart](/img/{{ img_dir }}/GameEngineFlowChart.png)

Upon a player bot's turn:
- The game engine requests an action from a player bot by passing the current game state to the bot.
- The player bot requests a list of all valid actions from the rules engine.
- On the basis of its internal logic, it chooses an action to perform and communicates this to the game engine.
- The game engine requests a list of all valid actions from the rules engine and ensures that the bot's chosen action is on this list.
- The game engine updates the game state and requests an action from the next player bot (repeat step 1 with the next player bot).

The double validation of rules ensures that no bot can cheat and potentially break the game state, making this engine suitable for tournaments and unsupervised play.

# Player Bots
Player bots are implementations of a simple API. Each bot consist of a single custom Python class that extends the PlayerInterface class. This class must implement a single method, `move()`, which communicates to the game engine what action to take in the form of a return value. This method should take two parameters, the ID of the active player (as bots don't know the ID that the game engine allocates), and a (deep) copy of the current game state. The permitted return values must be one of:

| Return Value | Description |
| ------------ | ----------- |
| `(MOVE_CAMEL_ACTION_ID, )` | Move a camel |
| `(MOVE_TRAP_ACTION_ID, trap_type, trap_location)` | Place a trap |
| `(ROUND_BET_ACTION_ID, camel_id)` | Make a bet on the round winner |
| `(GAME_BET_ACTION_ID, bet_type, camel_id)` | Make a bet on the game winner or loser |

The first elements of each tuple are defined in `actionids.py` and serve to ensure compatibility with future versions. The simply correspond to the integers 0 to 3.

To ensure error-free execution, it is advised to use the `get_valid_moves()` function to obtain a list of permissible actions. For an example on how to create a custom player bot, see the abstract superclass `playerinterface.PlayerInterface` as well as `bots.RandomBot`, which randomly selects an action to perform.

Player bots can see the current game state as well as all permitted rules. However, as the rules state that game winner and loser bets are secret, the bots are not given this information by the game engine. The engine achieves this by passing a modified (deep) copy of the game state to a player bot in which all game bets not made by the active player are set to `(None, None)`, i.e. the player bot will know how many bets were made but it will only know the details of the bets it made.

__WARNING:__ Python is not designed to be a "secure" programming language in that it is extremely difficult, if not impossible, to obfuscate the values of variables at runtime. A clever programmer will most likely be able to bypass the relatively simplistic security measures put into place to hide game bets. If this code is ever used in a tournament setting where cheating is to be avoided, manual inspection of the bot code is absolutely necessary. Rest assured, though, cheating will require programming tricks that an AI bot will not learn.
